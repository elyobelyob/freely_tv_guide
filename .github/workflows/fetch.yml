name: Fetch Freely Guide

on:
  workflow_dispatch:
    inputs:
      start:
        description: "UNIX timestamp for day start (UTC)"
        required: true
        default: "auto"
        type: string
      nid:
        description: "Freely nid"
        required: false
        default: "64865"
        type: string
  schedule:
    - cron: "0 */6 * * *"

jobs:
  fetch:
    runs-on: ubuntu-latest
    permissions:
      contents: write
      pages: write
      id-token: write
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install deps
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Compute default START (UK midnight if not provided)
        id: when
        shell: bash
        run: |
          if [[ -z "${{ github.event.inputs.start }}" || "${{ github.event.inputs.start }}" == "auto" ]]; then
            TZ=Europe/London START=$(date -d "$(date +%Y-%m-%d) 00:00:00" +%s)
          else
            START=${{ github.event.inputs.start }}
          fi
          echo "start=$START" >> "$GITHUB_OUTPUT"
          echo "nid=${{ github.event.inputs.nid || '64865' }}" >> "$GITHUB_OUTPUT"

      - name: Fetch & split
        run: |
          python scripts/freely_fetch_split.py --nid "${{ steps.when.outputs.nid }}" --start "${{ steps.when.outputs.start }}" --out docs

      - name: Mirror images (local-only, split folders) & rewrite JSON; clean orphans
        env:
          IMG_WORKERS: "12"
          IMG_HOURS_AHEAD: "48"   # only consider programme images starting within next N hours
        run: |
          python - <<'PY'
          import json, hashlib, pathlib, requests, concurrent.futures, os, datetime
          from urllib.parse import urlparse
      
          base = pathlib.Path('docs')
          chan_dir = base/'channels'
          img_prog = base/'img'/'programmes'
          img_chan = base/'img'/'channels'
          img_prog.mkdir(parents=True, exist_ok=True)
          img_chan.mkdir(parents=True, exist_ok=True)
      
          # placeholders
          prog_placeholder = img_prog/'placeholder.svg'
          chan_placeholder = img_chan/'placeholder.svg'
          if not prog_placeholder.exists():
              prog_placeholder.write_text(
                '<svg xmlns="http://www.w3.org/2000/svg" width="540" height="360"><rect width="100%" height="100%" fill="#e5e7eb"/><text x="50%" y="50%" dominant-baseline="middle" text-anchor="middle" font-family="Arial,Helvetica,sans-serif" font-size="20" fill="#6b7280">No image</text></svg>',
                'utf-8'
              )
          if not chan_placeholder.exists():
              chan_placeholder.write_text(
                '<svg xmlns="http://www.w3.org/2000/svg" width="256" height="256"><rect width="100%" height="100%" fill="#e5e7eb"/><text x="50%" y="50%" dominant-baseline="middle" text-anchor="middle" font-family="Arial,Helvetica,sans-serif" font-size="20" fill="#6b7280">No logo</text></svg>',
                'utf-8'
              )
      
          # HTTP session
          session = requests.Session()
          session.headers.update({
            "User-Agent":"Mozilla/5.0 (freely_tv_guide)",
            "Accept":"image/avif,image/webp,image/*,*/*;q=0.8",
            "Referer":"https://www.freeviewplay.co.uk/",  # friendlier than img.freeviewplay.tv
          })
      
          def guess_ext(url, content_type=None):
              if content_type:
                  ct = content_type.lower()
                  if 'jpeg' in ct or 'jpg' in ct: return '.jpg'
                  if 'png' in ct: return '.png'
                  if 'webp' in ct: return '.webp'
              p = urlparse(url).path.lower()
              for e in ('.jpg','.jpeg','.png','.webp'):
                  if p.endswith(e): return e
              return '.jpg'
      
          # Collect work: channel logos + programme images (next N hours)
          HOURS_AHEAD = int(os.getenv('IMG_HOURS_AHEAD','48'))
          now = datetime.datetime.utcnow().replace(tzinfo=datetime.timezone.utc)
          ahead = now + datetime.timedelta(hours=HOURS_AHEAD)
      
          # Each item: (kind, json_path(str), url_candidates[list])
          jobs = []  # kind in {"channel","programme"}
          files = list(chan_dir.glob('*.json'))
      
          for p in files:
              data = json.loads(p.read_text('utf-8'))
      
              # channel logo
              ch = data.get('channel') or {}
              logo = ch.get('logo')
              if logo:
                  jobs.append(("channel", str(p), [logo]))
      
              # programme images
              for ev in data.get('events', []):
                  st = ev.get('startTime')
                  try:
                      st_dt = datetime.datetime.fromisoformat(str(st).replace('Z','+00:00').replace('+0000','+00:00')) if st else None
                  except Exception:
                      st_dt = None
                  if st_dt and st_dt > ahead:
                      continue
                  raw = ev.get('_raw') or {}
                  cands = []
                  if ev.get('image'): cands.append(ev['image'])
                  if raw.get('image_url'): cands.append(raw['image_url'])
                  if raw.get('fallback_image_url'): cands.append(raw['fallback_image_url'])
                  if cands:
                      jobs.append(("programme", str(p), cands))
      
          # Download (parallel), always save; map url->relative path
          def download(kind, url):
              try:
                  r = session.get(url, timeout=12)
                  r.raise_for_status()
                  ext = guess_ext(url, r.headers.get('content-type','image/jpeg'))
                  h = hashlib.sha1(url.encode()).hexdigest() + ext
                  if kind == "channel":
                      (img_chan/h).write_bytes(r.content)
                      return f"img/channels/{h}"
                  else:
                      (img_prog/h).write_bytes(r.content)
                      return f"img/programmes/{h}"
              except Exception:
                  return None
      
          workers = int(os.getenv('IMG_WORKERS','12'))
          url_cache = {}  # (kind,url) -> relpath or None
          def ensure(kind, url):
              key = (kind, url)
              if key in url_cache:
                  return url_cache[key]
              res = download(kind, url)
              url_cache[key] = res
              return res
      
          # Rewrite JSONs; track referenced files for cleanup
          ref_prog = set()
          ref_chan = set()
      
          for p in files:
              changed = False
              data = json.loads(pathlib.Path(p).read_text('utf-8'))
      
              # channel logo
              ch = data.get('channel') or {}
              logo = ch.get('logo')
              if logo:
                  out = None
                  for u in [logo]:
                      out = ensure("channel", u)
                      if out: break
                  ch['logo'] = out or 'img/channels/placeholder.svg'
                  if out: ref_chan.add(pathlib.Path(out).name)
                  changed = True
      
              # programme images
              for ev in data.get('events', []):
                  raw = ev.get('_raw') or {}
                  cands = [ev.get('image'), raw.get('image_url'), raw.get('fallback_image_url')]
                  out = None
                  for u in cands:
                      if not u: continue
                      out = ensure("programme", u)
                      if out: break
                  ev['image'] = out or 'img/programmes/placeholder.svg'
                  if out: ref_prog.add(pathlib.Path(out).name)
                  changed = True
      
              if changed:
                  pathlib.Path(p).write_text(json.dumps(data, ensure_ascii=False, indent=2), 'utf-8')
      
          # Clean orphans (keep placeholders)
          for f in img_prog.glob('*'):
              if f.name in ('placeholder.svg',) or f.is_dir(): continue
              if f.name not in ref_prog:
                  try: f.unlink()
                  except: pass
          for f in img_chan.glob('*'):
              if f.name in ('placeholder.svg',) or f.is_dir(): continue
              if f.name not in ref_chan:
                  try: f.unlink()
                  except: pass
          PY


      - name: Update README channel list
        run: |
          python - <<'PY'
          import json, pathlib, re
          idx = json.loads(pathlib.Path('docs/index.json').read_text('utf-8'))
          base = 'https://elyobelyob.github.io/freely_tv_guide/'
          rows = ['| ID | Name | JSON |','|---:|---|---|']
          for c in idx.get('channels', []):
              rows.append(f"| {c['id']} | {c['name']} | [{c['path']}]({base}{c['path']}) |")
          table = '\n'.join(rows)
      
          readme_path = pathlib.Path('README.md')
          readme = readme_path.read_text('utf-8')
          start, end = '<!-- CHANNELS_START -->', '<!-- CHANNELS_END -->'
          pattern = re.compile(rf"{start}[\s\S]*?{end}", re.MULTILINE)
          if start in readme and end in readme:
            readme = pattern.sub(f"{start}\n{table}\n{end}", readme)
          else:
            readme += f"\n\n## Channel list\n{start}\n{table}\n{end}\n"
          readme_path.write_text(readme, 'utf-8')
          PY


      - name: Commit outputs
        run: |
          git config user.name "github-actions"
          git config user.email "github-actions@users.noreply.github.com"
          git add docs/
          if git diff --cached --quiet; then
            echo "No changes"
          else
            git commit -m "Update EPG: start=${{ steps.when.outputs.start }}"
            git push
          fi
