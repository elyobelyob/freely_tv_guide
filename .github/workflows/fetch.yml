name: Fetch Freely Guide

on:
  workflow_dispatch:
    inputs:
      start:
        description: "UNIX timestamp (leave blank or 'auto' for UK midnight today)"
        required: false
        type: string
        default: "auto"
      nid:
        description: "Freely nid"
        required: false
        type: string
        default: "64865"

  schedule:
    - cron: "5 4 * * *"   # runs daily at 04:05 UTC

jobs:
  fetch:
    runs-on: ubuntu-latest
    permissions:
      contents: write
      pages: write
      id-token: write
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'
          cache-dependency-path: |
            requirements.txt


      - name: Install deps
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Compute START (UTC midnight of UK day unless provided)
        id: when
        shell: bash
        run: |
          if [[ -z "${{ github.event.inputs.start }}" || "${{ github.event.inputs.start }}" == "auto" ]]; then
            UKDATE=$(TZ=Europe/London date +%Y-%m-%d)              # e.g. 2025-10-04
            START=$(date -u -d "$UKDATE 00:00:00" +%s)             # 00:00:00 UTC of that calendar date
          else
            START='${{ github.event.inputs.start }}'
          fi
          echo "start=$START" >> "$GITHUB_OUTPUT"
          echo "nid=${{ github.event.inputs.nid || '64865' }}" >> "$GITHUB_OUTPUT"

      - name: Show resolved START
        run: |
          echo "start=${{ steps.when.outputs.start }}"
          TZ=Europe/London date -d @${{ steps.when.outputs.start }} "+UK  %Y-%m-%d %H:%M (%Z)"
          date -u -d @${{ steps.when.outputs.start }} "+UTC %Y-%m-%d %H:%M"

      - name: Fetch & split
        run: |
          python scripts/freely_fetch_split.py \
            --nid "${{ steps.when.outputs.nid }}" \
            --start "${{ steps.when.outputs.start }}" \
            --out docs

      - name: Mirror images (fast cached) & rewrite JSON
        env:
          IMG_WORKERS: "16"          # parallel downloads
          IMG_HOURS_AHEAD: "18"      # only mirror programmes starting within next N hours
          IMG_MAX_PER_CHANNEL: "10"  # cap images per channel per run
          IMG_TIMEOUT_CONNECT: "4"
          IMG_TIMEOUT_READ: "8"
        run: |
          python - <<'PY'
          import json, hashlib, pathlib, requests, concurrent.futures, os, datetime, sys
          from urllib.parse import urlparse
      
          base = pathlib.Path('docs')
          chan_dir = base/'channels'
          img_prog = base/'img'/'programmes'
          img_chan = base/'img'/'channels'
          img_prog.mkdir(parents=True, exist_ok=True)
          img_chan.mkdir(parents=True, exist_ok=True)
      
          # placeholders
          def ensure_placeholder(p: pathlib.Path, text: str, w=540, h=360):
              if not p.exists():
                  p.write_text(
                    f'<svg xmlns="http://www.w3.org/2000/svg" width="{w}" height="{h}">'
                    f'<rect width="100%" height="100%" fill="#e5e7eb"/>'
                    f'<text x="50%" y="50%" dominant-baseline="middle" text-anchor="middle" '
                    f'font-family="Arial,Helvetica,sans-serif" font-size="20" fill="#6b7280">{text}</text>'
                    f'</svg>', 'utf-8'
                  )
          ensure_placeholder(img_prog/'placeholder.svg', 'No image', 540, 360)
          ensure_placeholder(img_chan/'placeholder.svg', 'No logo', 256, 256)
      
          # session
          session = requests.Session()
          session.headers.update({
            "User-Agent":"Mozilla/5.0 (freely_tv_guide)",
            "Accept":"image/avif,image/webp,image/*,*/*;q=0.8",
            "Referer":"https://www.freeviewplay.co.uk/",
          })
          TCON = float(os.getenv('IMG_TIMEOUT_CONNECT','4'))
          TREAD = float(os.getenv('IMG_TIMEOUT_READ','8'))
      
          def guess_ext(url, content_type=None):
            if content_type:
              ct = content_type.lower()
              if 'jpeg' in ct or 'jpg' in ct: return '.jpg'
              if 'png' in ct: return '.png'
              if 'webp' in ct: return '.webp'
            p = urlparse(url).path.lower()
            for e in ('.jpg','.jpeg','.png','.webp'):
              if p.endswith(e): return e
            return '.jpg'
      
          HOURS_AHEAD = int(os.getenv('IMG_HOURS_AHEAD','18'))
          MAX_PER_CH   = int(os.getenv('IMG_MAX_PER_CHANNEL','10'))
          now = datetime.datetime.utcnow().replace(tzinfo=datetime.timezone.utc)
          ahead = now + datetime.timedelta(hours=HOURS_AHEAD)
      
          # collect work
          jobs_prog = []         # programme image URL list
          jobs_chan = []         # (channel id, logo url)
          per_channel_count = {} # limit per channel
      
          json_files = list(chan_dir.glob('*.json'))
          for p in json_files:
            data = json.loads(p.read_text('utf-8'))
            ch = data.get('channel') or {}
            cid = ch.get('id')
            logo = ch.get('logo')
            if logo:
              jobs_chan.append((cid, logo))
      
            cnt = 0
            for ev in data.get('events', []):
              st = ev.get('startTime')
              try:
                st_dt = datetime.datetime.fromisoformat(str(st).replace('Z','+00:00').replace('+0000','+00:00')) if st else None
              except Exception:
                st_dt = None
              if st_dt and st_dt > ahead:
                continue
              if MAX_PER_CH and cnt >= MAX_PER_CH:
                continue
              raw = ev.get('_raw') or {}
              cands = [ev.get('image'), raw.get('image_url'), raw.get('fallback_image_url')]
              # first non-empty candidate
              for u in cands:
                if u:
                  jobs_prog.append(u)
                  cnt += 1
                  break
            per_channel_count[cid] = cnt
      
          # download logic (skip network if file already exists)
          def ensure_local(kind, url):
            if not url:
              return None
            h = hashlib.sha1(url.encode()).hexdigest()
            dest_dir = img_chan if kind == 'channel' else img_prog
            # try existing files (any known ext)
            for ext in ('.jpg','.jpeg','.png','.webp'):
              f = dest_dir/(h+ext)
              if f.exists():
                return f
            try:
              r = session.get(url, timeout=(TCON, TREAD))
              r.raise_for_status()
              ext = guess_ext(url, r.headers.get('content-type','image/jpeg'))
              f = dest_dir/(h+ext)
              f.write_bytes(r.content)
              return f
            except Exception:
              return None
      
          # parallel downloads
          workers = int(os.getenv('IMG_WORKERS','16'))
      
          # channels
          chan_map = {}  # cid/url -> rel path
          with concurrent.futures.ThreadPoolExecutor(max_workers=workers) as ex:
            futs = {ex.submit(ensure_local, 'channel', u): (cid, u) for cid,u in jobs_chan}
            for fut in concurrent.futures.as_completed(futs):
              cid, u = futs[fut]
              f = fut.result()
              chan_map[(cid,u)] = ('img/channels/'+f.name) if f else 'img/channels/placeholder.svg'
      
          # programmes (dedup urls)
          prog_urls = sorted(set([u for u in jobs_prog if u]))
          prog_map = {}
          with concurrent.futures.ThreadPoolExecutor(max_workers=workers) as ex:
            futs = {ex.submit(ensure_local, 'programme', u): u for u in prog_urls}
            for fut in concurrent.futures.as_completed(futs):
              u = futs[fut]
              f = fut.result()
              prog_map[u] = ('img/programmes/'+f.name) if f else 'img/programmes/placeholder.svg'
      
          # rewrite JSON + collect referenced files
          ref_prog = set(['placeholder.svg'])
          ref_chan = set(['placeholder.svg'])
          changed_files = 0
          for p in json_files:
            data = json.loads(p.read_text('utf-8'))
            ch = data.get('channel') or {}
            logo = ch.get('logo')
            if logo:
              ch['logo'] = chan_map.get((ch.get('id'), logo), 'img/channels/placeholder.svg')
              if ch['logo'].startswith('img/channels/'):
                ref_chan.add(pathlib.Path(ch['logo']).name)
            for ev in data.get('events', []):
              raw = ev.get('_raw') or {}
              for u in (ev.get('image'), raw.get('image_url'), raw.get('fallback_image_url')):
                if not u: 
                  continue
                rel = prog_map.get(u)
                if rel:
                  ev['image'] = rel
                  if rel.startswith('img/programmes/'):
                    ref_prog.add(pathlib.Path(rel).name)
                  break
              else:
                ev['image'] = 'img/programmes/placeholder.svg'
            p.write_text(json.dumps(data, ensure_ascii=False, indent=2), 'utf-8')
            changed_files += 1
      
          # clean orphans
          for f in img_prog.glob('*'):
            if f.name not in ref_prog and f.name != 'placeholder.svg':
              try: f.unlink()
              except: pass
          for f in img_chan.glob('*'):
            if f.name not in ref_chan and f.name != 'placeholder.svg':
              try: f.unlink()
              except: pass
      
          print(f"Channels processed: {len(json_files)}; programme images queued: {len(prog_urls)}; per-channel cap: {MAX_PER_CH}", file=sys.stderr)
          PY


      - name: Update README channel list
        run: |
          python - <<'PY'
          import json, pathlib, re
          idx = json.loads(pathlib.Path('docs/index.json').read_text('utf-8'))
          base = 'https://elyobelyob.github.io/freely_tv_guide/'
          rows = ['| ID | Name | JSON |','|---:|---|---|']
          for c in idx.get('channels', []):
              rows.append(f"| {c['id']} | {c['name']} | [{c['path']}]({base}{c['path']}) |")
          table = '\n'.join(rows)
      
          readme_path = pathlib.Path('README.md')
          readme = readme_path.read_text('utf-8')
          start, end = '<!-- CHANNELS_START -->', '<!-- CHANNELS_END -->'
          pattern = re.compile(rf"{start}[\s\S]*?{end}", re.MULTILINE)
          if start in readme and end in readme:
            readme = pattern.sub(f"{start}\n{table}\n{end}", readme)
          else:
            readme += f"\n\n## Channel list\n{start}\n{table}\n{end}\n"
          readme_path.write_text(readme, 'utf-8')
          PY

          
      - name: Add index pages for image folders (and disable Jekyll)
        run: |
          python - <<'PY'
          import pathlib, html
      
          root = pathlib.Path('docs')
          (root/'.nojekyll').write_text('', encoding='utf-8')  # ensure static serving
      
          def write_index(dirpath: pathlib.Path, title: str):
            dirpath.mkdir(parents=True, exist_ok=True)
            files = sorted(p.name for p in dirpath.glob('*') if p.is_file())
            thumbs = ''.join(
              f"<a href='{html.escape(n)}'><img src='{html.escape(n)}' alt='{html.escape(n)}'></a>"
              for n in files
            )
            html_doc = f"""<!doctype html>
            <meta charset="utf-8"><title>{html.escape(title)}</title>
            <style>
              body{{font-family:system-ui,Arial,sans-serif;padding:16px}}
              .grid{{display:grid;grid-template-columns:repeat(auto-fill,minmax(140px,1fr));gap:10px}}
              img{{max-width:100%;height:auto;border-radius:8px}}
              a{{text-decoration:none}}
            </style>
            <h1>{html.escape(title)}</h1>
            <div class="grid">{thumbs}</div>
            """
            (dirpath/'index.html').write_text(html_doc, encoding='utf-8')
      
          write_index(root/'img'/'programmes', 'Programme images')
          write_index(root/'img'/'channels',   'Channel logos')
          PY


      - name: Build stats page
        run: |
          python - <<'PY'
          import json, pathlib, datetime
      
          base = pathlib.Path('docs')
          (base/'.nojekyll').write_text('', encoding='utf-8')  # ensure static serving
      
          chan_dir = base/'channels'
          img_prog = base/'img'/'programmes'
          img_chan = base/'img'/'channels'
          stats_dir = base/'stats'
          stats_dir.mkdir(parents=True, exist_ok=True)
      
          # channels from index.json if present (falls back to file count)
          idx_path = base/'index.json'
          if idx_path.exists():
              idx = json.loads(idx_path.read_text('utf-8'))
              channels = idx.get('channels', [])
              channel_count = len(channels)
              start = idx.get('start')
          else:
              channels = sorted(p.name for p in chan_dir.glob('*.json'))
              channel_count = len(channels)
              start = None
      
          # count images (ignore placeholders)
          def count_images(p):
              if not p.exists(): return 0
              return sum(1 for f in p.glob('*') if f.is_file() and f.name != 'placeholder.svg')
      
          prog_images = count_images(img_prog)
          chan_images = count_images(img_chan)
      
          stats = {
            "channels": channel_count,
            "programme_images": prog_images,
            "channel_logos": chan_images,
            "start": start,
            "generated_utc": datetime.datetime.utcnow().isoformat(timespec='seconds') + 'Z'
          }
          (stats_dir/'stats.json').write_text(json.dumps(stats, indent=2), 'utf-8')
      
          # simple HTML
          html = f"""<!doctype html>
          <meta charset="utf-8">
          <title>Freely TV Guide — Stats</title>
          <style>
            :root {{ --bg:#0b1220; --fg:#e6eaf2; --muted:#9aa4b2; --card:#111a2e; }}
            body{{margin:0;background:var(--bg);color:var(--fg);font:16px/1.5 system-ui,Arial,sans-serif;padding:32px}}
            h1{{margin:0 0 18px 0;font-size:28px}}
            .grid{{display:grid;grid-template-columns:repeat(auto-fit,minmax(220px,1fr));gap:14px;margin:18px 0 8px}}
            .card{{background:var(--card);padding:18px 22px;border-radius:14px;box-shadow:0 1px 3px rgba(0,0,0,.4)}}
            .k{{font-size:12px;color:var(--muted);text-transform:uppercase;letter-spacing:.06em}}
            .v{{font-size:28px;font-weight:700}}
            a{{color:#7cc7ff;text-decoration:none}}
            .links a{{margin-right:14px}}
            .small{{color:var(--muted);font-size:13px}}
          </style>
          <h1>Freely TV Guide — Stats</h1>
          <div class="grid">
            <div class="card"><div class="k">Channels</div><div class="v">{channel_count}</div></div>
            <div class="card"><div class="k">Programme images</div><div class="v">{prog_images}</div></div>
            <div class="card"><div class="k">Channel logos</div><div class="v">{chan_images}</div></div>
          </div>
          <p class="small">Start timestamp: {start if start is not None else 'n/a'}<br>
          Generated (UTC): {stats['generated_utc']}</p>
          <p class="links">
            <a href="../index.json">index.json</a>
            <a href="../img/programmes/">programme images</a>
            <a href="../img/channels/">channel logos</a>
            <a href="stats.json">stats.json</a>
          </p>
          """
          (stats_dir/'index.html').write_text(html, 'utf-8')
          PY


      - name: Commit outputs
        run: |
          git config user.name "github-actions"
          git config user.email "github-actions@users.noreply.github.com"
          git add -A 
          if git diff --cached --quiet; then
            echo "No changes"
          else
            git commit -m "Update EPG: start=${{ steps.when.outputs.start }}"
            git push
          fi
